{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Anyone knows how much it costs to host a web portal ?\r\n",
      ">\r\n",
      "Well, it depends on how many visitors you're expecting.\r\n",
      "This can be anywhere from less than 10 bucks a month to a couple of $100. \r\n",
      "You should checkout http://www.rackspace.com/ or perhaps Amazon EC2 \r\n",
      "if youre running something big..\r\n",
      "\r\n",
      "To unsubscribe yourself from this mailing list, send an email to:\r\n",
      "groupname-unsubscribe@egroups.com\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Examples from the dataset\n",
    "!cat ex6/emailSample1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folks,\r\n",
      " \r\n",
      "my first time posting - have a bit of Unix experience, but am new to Linux.\r\n",
      "\r\n",
      " \r\n",
      "Just got a new PC at home - Dell box with Windows XP. Added a second hard disk\r\n",
      "for Linux. Partitioned the disk and have installed Suse 7.2 from CD, which went\r\n",
      "fine except it didn't pick up my monitor.\r\n",
      " \r\n",
      "I have a Dell branded E151FPp 15\" LCD flat panel monitor and a nVidia GeForce4\r\n",
      "Ti4200 video card, both of which are probably too new to feature in Suse's default\r\n",
      "set. I downloaded a driver from the nVidia website and installed it using RPM.\r\n",
      "Then I ran Sax2 (as was recommended in some postings I found on the net), but\r\n",
      "it still doesn't feature my video card in the available list. What next?\r\n",
      " \r\n",
      "Another problem. I have a Dell branded keyboard and if I hit Caps-Lock twice,\r\n",
      "the whole machine crashes (in Linux, not Windows) - even the on/off switch is\r\n",
      "inactive, leaving me to reach for the power cable instead.\r\n",
      " \r\n",
      "If anyone can help me in any way with these probs., I'd be really grateful -\r\n",
      "I've searched the 'net but have run out of ideas.\r\n",
      " \r\n",
      "Or should I be going for a different version of Linux such as RedHat? Opinions\r\n",
      "welcome.\r\n",
      " \r\n",
      "Thanks a lot,\r\n",
      "Peter\r\n",
      "\r\n",
      "-- \r\n",
      "Irish Linux Users' Group: ilug@linux.ie\r\n",
      "http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\r\n",
      "List maintainer: listmaster@linux.ie\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat ex6/emailSample2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk, nltk.stem.porter\n",
    "def processEmail(email):\n",
    "    \"\"\"Email preprocessing and normalization\"\"\"\n",
    "    \n",
    "    # Convert to lower-case\n",
    "    email = email.lower()\n",
    "    \n",
    "    # Strip HTML\n",
    "    email = BeautifulSoup(email, 'html.parser').get_text()\n",
    "    \n",
    "    # Normalize numbers\n",
    "    email = re.sub('[0-9]+','number',email)\n",
    "    \n",
    "    # Normalize URLs\n",
    "    email = re.sub('(http|https)://[^\\s]*', 'httpaddr', email)\n",
    "    \n",
    "    # Normalize emails\n",
    "    email = re.sub('[^\\s]+@[^\\s]+', 'emailaddr', email)\n",
    "    \n",
    "    # Normalize dollars\n",
    "    email = re.sub('[$]+', 'dollar', email)\n",
    "    \n",
    "    return email\n",
    "\n",
    "def tokenizeEmail(email):\n",
    "    \"\"\"\n",
    "    Convert email to token list.\n",
    "    \"\"\"\n",
    "    token_list = []\n",
    "    \n",
    "    # Pre-processing\n",
    "    email = processEmail(email)\n",
    "    \n",
    "    # Split into tokens\n",
    "    tokens = re.split('[ \\@\\$\\/\\#\\.\\-\\:\\&\\*\\+\\=\\[\\]\\?\\!\\(\\)\\{\\}\\,\\'\\\"\\>\\_\\<\\;\\%]', email)\n",
    "    \n",
    "    # Use porter stemmer to stem individual words in the email\n",
    "    # Stemmers remove derivational afixes.\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    \n",
    "    for word in tokens:\n",
    "        \n",
    "        # Remove non-alphanumeric characters\n",
    "        word = re.sub('[^a-zA-Z0-9]', '',word)\n",
    "        \n",
    "        # Stem\n",
    "        word = stemmer.stem(word)\n",
    "        if len(word) < 1: \n",
    "            continue\n",
    "        \n",
    "        token_list.append(word)\n",
    "    \n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getVocabList():\n",
    "    \"\"\"\n",
    "    Extract all words in vocabulary and their indices.\n",
    "    \"\"\"\n",
    "    vocabulary = {}\n",
    "    with open('ex6/vocab.txt') as vocab:\n",
    "        for line in vocab:\n",
    "            (index, word) = line.split()\n",
    "            vocabulary[word] = index\n",
    "            \n",
    "    return vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = getVocabList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emailIndices(email, vocabulary):\n",
    "    \"\"\"\n",
    "    Map words (tokens) from the email to indices in the vocabulary.\n",
    "    \"\"\"\n",
    "    # Get email tokens\n",
    "    email_tokens = tokenizeEmail(email)\n",
    "    \n",
    "    # Get email token indices\n",
    "    indices = [int(vocabulary[word]) for word in email_tokens if word in vocabulary]\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features from emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45]\n",
      "1899\n"
     ]
    }
   ],
   "source": [
    "def emailFeatures(email, vocabulary):\n",
    "    num_features = len(vocabulary)\n",
    "    features = np.zeros((num_features,1))\n",
    "    indices = emailIndices(email, vocabulary)\n",
    "    for index in indices:\n",
    "        features[index] = 1\n",
    "    return features\n",
    "\n",
    "# Once you have implemented emailFeatures, you should see that the feature\n",
    "# vector has length 1899 and 45 non-zero entries\n",
    "\n",
    "email_sample = open( 'ex6/emailSample1.txt', 'r' ).read()\n",
    "email_features = emailFeatures(email_sample, vocab)\n",
    "\n",
    "print sum(email_features == 1)\n",
    "print len(email_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SVM for Spam Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99825\n",
      "0.989\n"
     ]
    }
   ],
   "source": [
    "# Load training and test data\n",
    "training_data = sio.loadmat('ex6/spamTrain.mat')\n",
    "testing_data = sio.loadmat('ex6/spamTest.mat')\n",
    "\n",
    "# Labels and feature vectors\n",
    "X, Y = training_data['X'], training_data['y']\n",
    "Xtest , Ytest = testing_data['Xtest'], testing_data['ytest']\n",
    "\n",
    "# Train classifier on training data\n",
    "C = 0.1\n",
    "model = svm.SVC(C=C, kernel='linear')\n",
    "model.fit(X,Y.ravel())\n",
    "\n",
    "# Once the training completes, you should see that the classifier gets,\n",
    "# a training accuracy of about 99.8% and a test accuracy of about 98.5%\n",
    "\n",
    "print model.score(X,Y)\n",
    "print model.score(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top predictors for spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearest indicators of spam are:\n",
      "* otherwis\n",
      "* clearli\n",
      "* remot\n",
      "* gt\n",
      "* visa\n",
      "* base\n",
      "* doesn\n",
      "* wife\n",
      "* previous\n",
      "* player\n",
      "* mortgag\n",
      "* natur\n",
      "* ll\n",
      "* futur\n",
      "* hot\n",
      "* air\n",
      "* cv\n",
      "* script\n",
      "* wall\n",
      "* dollarac\n",
      "* believ\n",
      "* entri\n",
      "* receiv\n",
      "* numberanumb\n",
      "* creativ\n",
      "* multi\n",
      "* page\n",
      "* boi\n",
      "* black\n",
      "* weblog\n"
     ]
    }
   ],
   "source": [
    "# Determine what are the words with the highest weights in the classifier \n",
    "# = words that are most likely indicators of spam.\n",
    "sorted_indices = np.argsort( model.coef_, axis=None )[::-1]\n",
    "\n",
    "vocabulary = {}\n",
    "with open('ex6/vocab.txt') as vocab:\n",
    "    for line in vocab:\n",
    "        (index, word) = line.split()\n",
    "        vocabulary[int(index)] = word\n",
    "\n",
    "print \"Clearest indicators of spam are:\"\n",
    "for i in range(30):\n",
    "    idx = sorted_indices[i]\n",
    "    print '* ' + vocabulary[idx]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
